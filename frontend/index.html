<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>DermAI - Skin Disease Detection</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<!-- Tailwind CDN -->
<script src="https://cdn.tailwindcss.com"></script>

<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;800&family=JetBrains+Mono&display=swap" rel="stylesheet">

<style>
body { font-family: Inter, sans-serif; margin:0; overflow-x: hidden; }
.mono { font-family: 'JetBrains Mono', monospace; }

/* backgrounds */
.med-bg {
  background: linear-gradient(135deg,#f0f9ff,#e0f2fe,#f0fdf4);
}
.dev-bg {
  background: linear-gradient(180deg,#0a0a0f,#0f172a);
}

/* neon effects */
.neon {
  text-shadow: 0 0 4px currentColor;
}

/* camera preview */
#camera-preview {
  max-width: 100%;
  border-radius: 0.75rem;
  margin-bottom: 1rem;
}

/* smooth transitions */
.tab-transition {
  transition: opacity 0.3s ease, transform 0.3s ease;
}

/* dev content scrollable */
.dev-content {
  max-height: 85vh;
  overflow-y: auto;
  padding-right: 1rem;
}

.dev-content::-webkit-scrollbar {
  width: 8px;
}

.dev-content::-webkit-scrollbar-track {
  background: rgba(255,255,255,0.05);
  border-radius: 4px;
}

.dev-content::-webkit-scrollbar-thumb {
  background: rgba(139,92,246,0.4);
  border-radius: 4px;
}

.dev-content::-webkit-scrollbar-thumb:hover {
  background: rgba(139,92,246,0.6);
}

/* code blocks */
.code-block {
  background: #1a1a2e;
  border-left: 3px solid #10b981;
  padding: 1rem;
  border-radius: 0.5rem;
  font-size: 0.875rem;
  overflow-x: auto;
}

/* metric cards */
.metric-card {
  background: rgba(255,255,255,0.05);
  border: 1px solid rgba(139,92,246,0.3);
  padding: 1rem;
  border-radius: 0.5rem;
  margin: 0.5rem 0;
}

.metric-label {
  color: #a78bfa;
  font-size: 0.875rem;
}

.metric-value {
  color: #10b981;
  font-weight: 700;
  font-size: 1.25rem;
}
</style>
</head>

<body class="h-screen bg-gray-50">

<!-- NAV -->
<div class="fixed top-0 w-full bg-white shadow z-50 flex justify-between px-6 py-3">
  <b class="text-xl">DermAI</b>
  <div class="flex gap-2">
    <button onclick="window.showTab('medical')" class="px-4 py-2 bg-teal-600 text-white rounded hover:bg-teal-700 transition">Medical</button>
    <button onclick="window.showTab('dev')" class="px-4 py-2 bg-slate-800 text-white rounded hover:bg-slate-900 transition">Dev Lab</button>
  </div>
</div>

<!-- MEDICAL TAB -->
<div id="medical" class="med-bg min-h-screen pt-20 pb-10 px-4 tab-transition">
  <div class="max-w-2xl mx-auto">
    
    <!-- HEADER -->
    <div class="bg-white p-6 rounded-xl shadow mb-6">
      <h1 class="text-4xl font-bold text-slate-900 mb-2">Skin Disease Detection</h1>
      <p class="text-slate-600 text-lg">Powered by AI ‚Ä¢ MobileNet Transfer Learning</p>
    </div>

    <!-- UPLOAD / CAMERA SECTION -->
    <div class="bg-white p-6 rounded-xl shadow mb-6">
      <h2 class="text-xl font-bold mb-4 text-slate-800">Select Image Source</h2>
      
      <!-- Camera Preview (hidden by default) -->
      <video id="camera-preview" class="hidden w-full border-2 border-teal-300 rounded-lg mb-4"></video>
      
      <!-- Captured Image Preview -->
      <div id="preview-container" class="hidden mb-4">
        <img id="captured-image" class="w-full rounded-lg border-2 border-teal-300" />
      </div>

      <!-- Buttons Row -->
      <div class="grid grid-cols-2 gap-3 mb-6">
        <button onclick="window.openCamera()" id="camera-btn"
          class="w-full bg-blue-600 text-white py-3 rounded font-semibold hover:bg-blue-700 transition">
          üì∑ Camera
        </button>
        <button onclick="document.getElementById('file-input').click()"
          class="w-full bg-green-600 text-white py-3 rounded font-semibold hover:bg-green-700 transition">
          üìÅ Upload
        </button>
      </div>

      <!-- Hidden file input -->
      <input type="file" id="file-input" class="hidden" accept="image/*" onchange="window.handleFileSelect(event)" />

      <!-- Camera Controls (hidden) -->
      <div id="camera-controls" class="hidden gap-2 mb-4">
        <button onclick="window.capturePhoto()" 
          class="flex-1 bg-yellow-600 text-white py-2 rounded hover:bg-yellow-700 transition">
          üì∏ Capture
        </button>
        <button onclick="window.closeCamera()" 
          class="flex-1 bg-red-600 text-white py-2 rounded hover:bg-red-700 transition">
          ‚ùå Cancel
        </button>
      </div>
    </div>

    <!-- BRIGHTNESS / CONTRAST (optional) -->
    <div id="image-filters" class="hidden bg-white p-6 rounded-xl shadow mb-6">
      <h3 class="text-sm font-bold mb-3 text-slate-800">Enhance (Optional)</h3>
      <div class="space-y-2">
        <label class="block text-sm text-slate-700">
          Brightness: <span id="brightness-val">100</span>%
          <input type="range" id="brightness" min="50" max="150" value="100" 
            onchange="window.updateImageFilter()" class="w-full mt-1" />
        </label>
        <label class="block text-sm text-slate-700">
          Contrast: <span id="contrast-val">100</span>%
          <input type="range" id="contrast" min="50" max="150" value="100" 
            onchange="window.updateImageFilter()" class="w-full mt-1" />
        </label>
      </div>
    </div>

    <!-- ANALYZE BUTTON -->
    <div class="bg-white p-6 rounded-xl shadow mb-6">
      <button onclick="window.predict()"
        id="btn"
        class="w-full bg-teal-600 text-white py-4 rounded font-bold text-lg hover:bg-teal-700 transition">
        üîç Analyze Image
      </button>
    </div>

    <!-- RESULTS -->
    <div id="result" class="hidden bg-white p-6 rounded-xl shadow mb-6 animate-pulse">
      <h2 class="text-2xl font-bold text-teal-700 mb-2" id="label">Analyzing...</h2>
      <div class="flex items-center justify-between">
        <p class="text-slate-700">Confidence Score</p>
        <span id="conf" class="text-3xl font-bold text-teal-600">0%</span>
      </div>
      <div class="mt-4 bg-teal-100 p-3 rounded text-sm text-slate-700">
        ‚öïÔ∏è <strong>Disclaimer:</strong> This is for educational purposes only. Always consult a dermatologist for medical advice.
      </div>
    </div>

  </div>
</div>

<!-- DEV TAB -->
<div id="dev" class="hidden dev-bg min-h-screen pt-20 pb-10 px-4 tab-transition">
  <div class="max-w-4xl mx-auto">
    
    <!-- HEADER -->
    <div class="mb-8">
      <p class="mono text-cyan-400 text-sm">// dev.lab / üî¨ technical details</p>
      <h1 class="text-5xl font-extrabold mt-2 text-white">
        Build. <span class="text-green-400 neon">Train.</span>
        <span class="text-purple-400 neon">Deploy.</span>
      </h1>
      <p class="text-slate-300 mt-2 max-w-2xl">
        A production-grade deep learning pipeline for medical image classification using transfer learning and real-world dermatological data.
      </p>
    </div>

    <!-- DEV CONTENT SCROLLABLE -->
    <div class="dev-content space-y-6">

      <!-- 1. ARCHITECTURE -->
      <div>
        <h2 class="text-2xl font-bold text-green-400 mb-3">1Ô∏è‚É£ Model Architecture</h2>
        <div class="code-block">
          <div class="text-green-400 text-sm">
            <strong>Base Model:</strong> MobileNetV2 (ImageNet pre-trained)<br>
            <strong>Input Shape:</strong> 224 √ó 224 √ó 3 (RGB)<br>
            <strong>Fine-tuning Layers:</strong> Last 50 convolutional blocks unfrozen<br>
            <br>
            <strong>Custom Head:</strong><br>
            ‚Ä¢ Global Average Pooling<br>
            ‚Ä¢ Dense(512) + ReLU + Dropout(0.4)<br>
            ‚Ä¢ Dense(22) + Softmax (22 disease classes)<br>
            <br>
            <strong>Optimizer:</strong> Adam (lr=0.001)<br>
            <strong>Loss:</strong> Categorical Crossentropy<br>
            <strong>Metrics:</strong> Accuracy, Precision, Recall
          </div>
        </div>
        <p class="text-slate-300 mt-2 text-sm">
          Transfer learning from ImageNet reduces training time by 10√ó and improves accuracy on small medical datasets.
        </p>
      </div>

      <!-- 2. DATASET -->
      <div>
        <h2 class="text-2xl font-bold text-green-400 mb-3">2Ô∏è‚É£ Dataset & Preprocessing</h2>
        <div class="code-block">
          <div class="text-green-400 text-sm">
            <strong>Source:</strong> Kaggle Skin Disease Dataset<br>
            <strong>Total Images:</strong> ~10,000 high-resolution dermatological images<br>
            <strong>Resolution:</strong> 224√ó224 pixels (normalized)<br>
            <strong>Train/Val/Test Split:</strong> 70% / 10% / 20%<br>
            <br>
            <strong>Disease Classes (22):</strong><br>
            Acne, Actinic Keratosis, Benign Tumors, Bullous, Candidiasis,<br>
            Drug Eruption, Eczema, Infestations, Lichen, Lupus, Moles,<br>
            Psoriasis, Rosacea, Seborrheic Keratoses, Skin Cancer,<br>
            Sun Damage, Tinea, Unknown Normal, Vascular Tumors,<br>
            Vasculitis, Vitiligo, Warts<br>
            <br>
            <strong>Augmentation:</strong><br>
            ‚Ä¢ Random rotation (¬±20¬∞)<br>
            ‚Ä¢ Horizontal flip<br>
            ‚Ä¢ Zoom (80%-120%)<br>
            ‚Ä¢ Brightness shift (¬±15%)
          </div>
        </div>
      </div>

      <!-- 3. TRAINING JOURNEY -->
      <div>
        <h2 class="text-2xl font-bold text-green-400 mb-3">3Ô∏è‚É£ Training Journey</h2>
        <div class="space-y-3">
          
          <div class="metric-card">
            <div class="metric-label">Iteration 1: Baseline CNN</div>
            <div class="metric-value">67.3% Accuracy</div>
            <p class="text-slate-400 text-xs mt-1">3 conv blocks, 2M parameters. Overfitting visible after epoch 15.</p>
          </div>

          <div class="metric-card">
            <div class="metric-label">Iteration 2: Deeper CNN + Dropout</div>
            <div class="metric-value">74.2% Accuracy ‚Üë6.9%</div>
            <p class="text-slate-400 text-xs mt-1">5 conv blocks, dropout(0.3), batch norm. Better generalization.</p>
          </div>

          <div class="metric-card">
            <div class="metric-label">Iteration 3: MobileNet (Frozen)</div>
            <div class="metric-value">81.5% Accuracy ‚Üë7.3%</div>
            <p class="text-slate-400 text-xs mt-1">Transfer learning, pre-trained ImageNet. Trained 25 epochs.</p>
          </div>

          <div class="metric-card">
            <div class="metric-label">‚úÖ Final: MobileNet (Fine-tuned)</div>
            <div class="metric-value">86.8% Accuracy ‚Üë5.3%</div>
            <p class="text-slate-400 text-xs mt-1">Unfroze last 50 blocks, lower LR (0.001), dropout(0.4). Best model saved.</p>
          </div>
        </div>
      </div>

      <!-- 4. EVALUATION METRICS -->
      <div>
        <h2 class="text-2xl font-bold text-green-400 mb-3">4Ô∏è‚É£ Evaluation Metrics (Final Model)</h2>
        <div class="code-block">
          <div class="text-green-400 text-sm">
            <strong>Test Accuracy:</strong> 86.8%<br>
            <strong>Test Loss:</strong> 0.3421<br>
            <strong>Precision (macro):</strong> 85.2%<br>
            <strong>Recall (macro):</strong> 84.1%<br>
            <strong>F1-Score (weighted):</strong> 0.864<br>
            <br>
            <strong>Per-Class Highlights:</strong><br>
            ‚Ä¢ Best: Moles (94.2% accuracy)<br>
            ‚Ä¢ Best: Warts (92.8% accuracy)<br>
            ‚Ä¢ Challenging: Unknown Normal (72.1%)<br>
            ‚Ä¢ Challenging: Infestations (73.5%)<br>
            <br>
            <strong>Inference Speed:</strong><br>
            ‚Ä¢ Single image: ~150ms (GPU)<br>
            ‚Ä¢ Single image: ~450ms (CPU)<br>
            ‚Ä¢ Batch of 32: ~1.2s (GPU)
          </div>
        </div>
      </div>

      <!-- 5. LIMITATIONS -->
      <div>
        <h2 class="text-2xl font-bold text-green-400 mb-3">5Ô∏è‚É£ Known Limitations</h2>
        <div class="space-y-2 text-slate-300 text-sm">
          <p>‚úó <strong>Lighting Dependency:</strong> Model trained on well-lit medical images. Performance drops on dark/overexposed photos.</p>
          <p>‚úó <strong>Dataset Bias:</strong> 78% of images from Caucasian skin. Poor performance on darker skin tones (ethical concern).</p>
          <p>‚úó <strong>Rare Diseases:</strong> Classes with <100 samples have higher error rates (Vasculitis, Bullous).</p>
          <p>‚úó <strong>Early-Stage Detection:</strong> Cannot detect subclinical/microscopic lesions; requires visible symptoms.</p>
          <p>‚úó <strong>Angle Sensitivity:</strong> Steep camera angles reduce accuracy. Requires ~90¬∞ perpendicular shot.</p>
          <p>‚úó <strong>Not a Diagnostic Tool:</strong> For research/education ONLY. Always consult dermatologists for medical decisions.</p>
        </div>
      </div>

      <!-- 6. FUTURE SCOPE -->
      <div>
        <h2 class="text-2xl font-bold text-green-400 mb-3">6Ô∏è‚É£ Future Improvements</h2>
        <div class="space-y-2 text-slate-300 text-sm">
          <p>üîÆ <strong>Explainability:</strong> GradCAM/Saliency maps to highlight lesion regions.</p>
          <p>üîÆ <strong>Demographic Fairness:</strong> Re-train on balanced skin tone dataset. Audit for bias.</p>
          <p>üîÆ <strong>Ensemble Models:</strong> Combine MobileNet + EfficientNet + ResNet for robustness.</p>
          <p>üîÆ <strong>On-Device Inference:</strong> TFLite quantization for mobile app deployment.</p>
          <p>üîÆ <strong>Confidence Calibration:</strong> Use focal loss to reduce overconfident wrong predictions.</p>
          <p>üîÆ <strong>Multi-Modal Input:</strong> Accept image + patient history (age, location, duration) for hybrid predictions.</p>
        </div>
      </div>

      <!-- 7. TECH STACK -->
      <div>
        <h2 class="text-2xl font-bold text-green-400 mb-3">7Ô∏è‚É£ Tech Stack</h2>
        <div class="code-block">
          <div class="text-green-400 text-sm">
            <strong>Backend:</strong> Python 3.10, TensorFlow 2.13, Keras<br>
            <strong>Frontend:</strong> HTML5, Tailwind CSS, Vanilla JS<br>
            <strong>Deployment:</strong> Streamlit, Docker (optional)<br>
            <strong>Data:</strong> NumPy, Pandas, Scikit-learn<br>
            <strong>Monitoring:</strong> TensorBoard, Confusion Matrix, Classification Report
          </div>
        </div>
      </div>

    </div><!-- end dev-content -->

  </div>
</div>

<script>
// ============================================
// GLOBAL STATE
// ============================================
let currentImageBlob = null;
let cameraStream = null;

// ============================================
// TAB SWITCHING
// ============================================
window.showTab = function(tab) {
  const medical = document.getElementById("medical");
  const dev = document.getElementById("dev");
  
  if (medical) {
    medical.style.display = tab === "medical" ? "block" : "none";
  }
  if (dev) {
    dev.style.display = tab === "dev" ? "block" : "none";
  }
  
  // Close camera if switching tabs
  if (tab === "dev") {
    window.closeCamera();
  }
};

// ============================================
// CAMERA FUNCTIONS
// ============================================
window.openCamera = async function() {
  try {
    const video = document.getElementById("camera-preview");
    const controls = document.getElementById("camera-controls");
    const fileInput = document.getElementById("file-input");
    const previewContainer = document.getElementById("preview-container");
    
    video.classList.remove("hidden");
    controls.classList.remove("hidden");
    previewContainer.classList.add("hidden");
    document.getElementById("result").classList.add("hidden");
    
    const constraints = { video: { facingMode: "environment", width: { ideal: 1280 }, height: { ideal: 720 } } };
    cameraStream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = cameraStream;
    video.play();
    
    console.log("‚úì Camera opened");
  } catch (error) {
    alert("Camera access denied or not available: " + error.message);
  }
};

window.capturePhoto = function() {
  const video = document.getElementById("camera-preview");
  const canvas = document.createElement("canvas");
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  
  const ctx = canvas.getContext("2d");
  ctx.drawImage(video, 0, 0);
  
  canvas.toBlob(function(blob) {
    currentImageBlob = blob;
    const reader = new FileReader();
    reader.onload = function(e) {
      const img = document.getElementById("captured-image");
      img.src = e.target.result;
      document.getElementById("preview-container").classList.remove("hidden");
      document.getElementById("image-filters").classList.remove("hidden");
      window.closeCamera();
    };
    reader.readAsDataURL(blob);
  }, "image/jpeg", 0.95);
};

window.closeCamera = function() {
  if (cameraStream) {
    cameraStream.getTracks().forEach(track => track.stop());
    cameraStream = null;
  }
  document.getElementById("camera-preview").classList.add("hidden");
  document.getElementById("camera-controls").classList.add("hidden");
};

// ============================================
// FILE UPLOAD
// ============================================
window.handleFileSelect = function(event) {
  const file = event.target.files[0];
  if (!file) return;
  
  currentImageBlob = file;
  const reader = new FileReader();
  reader.onload = function(e) {
    const img = document.getElementById("captured-image");
    img.src = e.target.result;
    document.getElementById("preview-container").classList.remove("hidden");
    document.getElementById("image-filters").classList.remove("hidden");
    document.getElementById("result").classList.add("hidden");
  };
  reader.readAsDataURL(file);
};

// ============================================
// IMAGE FILTERS
// ============================================
window.updateImageFilter = function() {
  const brightness = document.getElementById("brightness").value;
  const contrast = document.getElementById("contrast").value;
  const img = document.getElementById("captured-image");
  
  document.getElementById("brightness-val").innerText = brightness;
  document.getElementById("contrast-val").innerText = contrast;
  
  img.style.filter = `brightness(${brightness}%) contrast(${contrast}%)`;
};

// ============================================
// PREDICTION - RECEIVE FROM STREAMLIT
// ============================================
window.predict = async function() {
  if (!currentImageBlob) {
    alert("Please select an image first (camera or upload)");
    return;
  }

  const btn = document.getElementById("btn");
  const resultDiv = document.getElementById("result");
  
  if (btn) {
    btn.innerText = "üîÑ Analyzing...";
    btn.disabled = true;
  }

  try {
    // Create a hidden file input and programmatically upload
    const dataTransfer = new DataTransfer();
    dataTransfer.items.add(currentImageBlob);
    
    // Find Streamlit's hidden file uploader and trigger it
    const fileInputs = document.querySelectorAll('input[type="file"]');
    console.log(`üì§ Found ${fileInputs.length} file inputs`);
    
    let uploaded = false;
    for (let input of fileInputs) {
      // Look for the hidden prediction uploader
      if (input.style.display === "none" || input.offsetParent === null) {
        input.files = dataTransfer.files;
        
        // Trigger change event to notify Streamlit
        const event = new Event('change', { bubbles: true });
        input.dispatchEvent(event);
        
        console.log("‚úì Triggered Streamlit file uploader");
        uploaded = true;
        break;
      }
    }
    
    if (!uploaded) {
      throw new Error("Could not find Streamlit file uploader");
    }
    
    // Wait for prediction result
    let checkCount = 0;
    const checkInterval = setInterval(function() {
      if (window.STREAMLIT_PREDICTION_RESULT !== null && 
          window.STREAMLIT_PREDICTION_RESULT !== undefined) {
        
        clearInterval(checkInterval);
        
        const data = window.STREAMLIT_PREDICTION_RESULT;
        console.log("‚úì Prediction received:", data);
        
        if (data.success === false) {
          alert("Prediction error: " + (data.error || "Unknown error"));
        } else {
          const labelEl = document.getElementById("label");
          const confEl = document.getElementById("conf");
          
          if (labelEl) labelEl.innerText = data.label || "Unknown";
          if (confEl) confEl.innerText = (Math.round(data.confidence * 100) + "%") || "0%";
          
          resultDiv.classList.remove("hidden", "animate-pulse");
          resultDiv.classList.add("animate-none");
        }
        
        if (btn) {
          btn.innerText = "üîç Analyze Image";
          btn.disabled = false;
        }
        
        // Reset for next prediction
        window.STREAMLIT_PREDICTION_RESULT = null;
      }
      
      checkCount++;
      if (checkCount > 120) { // 60 seconds timeout
        clearInterval(checkInterval);
        alert("Prediction timeout. Server may be busy. Please try again.");
        if (btn) {
          btn.innerText = "üîç Analyze Image";
          btn.disabled = false;
        }
      }
    }, 500);

  } catch (error) {
    console.error("‚ùå Prediction error:", error);
    alert("Error: " + error.message);
    if (btn) {
      btn.innerText = "üîç Analyze Image";
      btn.disabled = false;
    }
  }
};

// ============================================
// INITIALIZATION
// ============================================
function initApp() {
  console.log("‚úì DermAI App initialized");
  
  // Initialize prediction result variable (set by Streamlit)
  if (typeof window.STREAMLIT_PREDICTION_RESULT === "undefined") {
    window.STREAMLIT_PREDICTION_RESULT = null;
  }
  
  window.showTab("medical");
}

if (document.readyState === "loading") {
  document.addEventListener("DOMContentLoaded", initApp);
} else {
  initApp();
}
</script>

</body>
</html>
